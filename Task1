"""
1. Напишите функцию, которая получает на вход директорию и рекурсивно обходит её и все вложенные директории.
Результаты обхода сохраните в файлы json, csv и pickle.
○ Для дочерних объектов указывайте родительскую директорию.
○ Для каждого объекта укажите файл это или директория.
○ Для файлов сохраните его размер в байтах, а для директорий размер файлов в ней с учётом всех вложенных файлов и директорий.
2. Соберите из созданных на уроке и в рамках домашнего задания функций пакет для работы с файлами разных форматов.
"""

import os
import json
import csv
from pathlib import Path
import pickle
import argparse




def walk_directory(directory, parent=None) -> list:
    """Функция для обхода содержимого дирректории и анализа результата поиска"""
    result = []

    # Получаем содержимое текущей директории
    items = os.listdir(directory)

    total_size = 0  # Переменная для хранения общего размера директории

    for item in items:
        full_path = os.path.join(directory, item)

        if os.path.isdir(full_path):  # Если это директория
            entry = {
                'type': 'directory', # Присвоение тип
                'name': item, # Название директории
                'path': full_path, # полный путь до директории
                'parent': Path(directory).name
            }
            result.append(entry)

            # Рекурсивный вызов для обработки вложенных директорий
            sub_result, sub_total_size = walk_directory(full_path, entry['name'])
            result.extend(sub_result)
            total_size += sub_total_size

        else:  # Если это файл
            size = os.path.getsize(full_path)  # Определяем размер файла
            entry = {
                'type': 'file', # Присвоение тип
                'name': item, # Название файла
                'path': full_path, # полный путь до файла
                'parent': Path(directory).name, # Добавляю родительскую дирректорию (соотвестствует name родителя)
                'size': size # Добавляю размер файла
            }
            result.append(entry)
            total_size += size


    # result['total_size'] = total_size
    print(result[0])
    result[0]['total_size'] = total_size # Добавляем общий размер директории

    return result, total_size


def save_to_json(data, filename):
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=4, ensure_ascii=False)


def save_to_csv(data, filename):
    fieldnames = ['type', 'name', 'path', 'parent']

    with open(filename, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(data)


def save_to_pickle(data, filename):
    with open(filename, 'wb') as f:
        pickle.dump(data, f)


# Основная программа
if __name__ == "__main__":
    """Код начинает работать от сюда"""

    parser = argparse.ArgumentParser()

    parser.add_argument('dir', type=str, help="Ссылка на локальную директорию") # Принимает локальную ссылку на дирректорию
    parser.add_argument('--csv', action='store_true', help="Сохранить в csv") # Флаг на то что файл надо сохранить только в csv
    parser.add_argument('--pkl', action='store_true', help="Сохранить в pkl") # Флаг на то что файл надо сохранить только в pkl
    parser.add_argument('--json', action='store_true', help="Сохранить в json") # Флаг на то что файл надо сохранить только в json

    # parser.add_argument('-num', '--num', type=int, default=1,
    #                     help='Количество создаваемых файлов')

    args = parser.parse_args()

    # input_directory = r'D:\GeekBrains' # Дирректория для анализа ее содержимого
    input_directory = args.dir
    output_json_file = 'output.json'
    output_csv_file = 'output.csv'
    output_pickle_file = 'output.pkl'

    print(args.csv, args.pkl, args.json)

    # data = walk_directory(input_directory)

    if args.csv == True:
        save_to_json(data, 'output.csv')
    if args.pkl == True:
        save_to_pickle(data, 'output.pkl')
    if args.json == True:
        save_to_json(data, 'output.json')
    else:
        save_to_json(data, 'output.json')
        save_to_csv(data, 'output.csv')
        save_to_pickle(data, 'output.pkl')
